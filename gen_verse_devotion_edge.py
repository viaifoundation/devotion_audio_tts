import asyncio
import sys
import edge_tts
from pydub import AudioSegment
import os
from bible_parser import convert_bible_reference
from date_parser import convert_dates_in_text
from text_cleaner import clean_text
import filename_parser
import re
from datetime import datetime

TTS_RATE = "+10%"  # Speed up by 10%

import argparse

import audio_mixer

# CLI Args
if "-?" in sys.argv:
    print(f"Usage: python {sys.argv[0]} [--prefix PREFIX] [--speed SPEED] [--bgm] [--bgm-track TRACK] [--bgm-volume VOL] [--bgm-intro MS] [--help]")
    print("Options:")
    print("  --prefix PREFIX      Filename prefix (e.g. MyPrefix)")
    print("  --speed SPEED        Speech rate adjustment (e.g. +10%, -5%)")
    print("  --bgm                Enable background music (Default: False)")
    print("  --bgm-track TRACK    Specific BGM filename (Default: AmazingGrace.MP3)")
    print("  --bgm-volume VOL     BGM volume adjustment in dB (Default: -12)")
    print("  --bgm-intro MS       BGM intro delay in ms (Default: 4000)")
    print("  --help, -h           Show this help")
    sys.exit(0)

parser = argparse.ArgumentParser()
parser.add_argument("--prefix", type=str, default=None, help="Filename prefix (e.g. MyPrefix)")
parser.add_argument("--speed", type=str, default=None, help="Speech rate adjustment (e.g. +10%%)")
parser.add_argument("--bgm", action="store_true", help="Enable background music (Default: False)")
parser.add_argument("--bgm-track", type=str, default="AmazingGrace.MP3", help="Specific BGM filename (Default: AmazingGrace.MP3)")
parser.add_argument("--bgm-volume", type=int, default=-12, help="BGM volume adjustment in dB (Default: -12)")
parser.add_argument("--bgm-intro", type=int, default=4000, help="BGM intro delay in ms (Default: 4000)")

args, unknown = parser.parse_known_args()
CLI_PREFIX = args.prefix

ENABLE_BGM = args.bgm
BGM_FILE = args.bgm_track
BGM_VOLUME = args.bgm_volume
BGM_INTRO_DELAY = args.bgm_intro

if args.speed:
    if not "%" in args.speed and (args.speed.startswith("+") or args.speed.startswith("-") or args.speed.isdigit()):
        TTS_RATE = f"{args.speed}%"
    else:
        TTS_RATE = args.speed

# Cleaned Chinese devotional text (replace with actual text)
TEXT = """
è¶…è¶Šå¸¸è§„çš„ä¿¡å¿ƒ (è·¯åŠ ç¦éŸ³ 1:45) 12/20/2025

å¤©ä½¿å¯¹å¦‡å¥³è¯´ï¼šâ€œä¸è¦å®³æ€•ï¼æˆ‘çŸ¥é“ä½ ä»¬æ˜¯å¯»æ‰¾é‚£é’‰åå­—æ¶çš„è€¶ç¨£ã€‚ä»–ä¸åœ¨è¿™é‡Œï¼Œç…§ä»–æ‰€è¯´çš„ï¼Œå·²ç»å¤æ´»äº†ã€‚ä½ ä»¬æ¥çœ‹å®‰æ”¾ä¸»çš„åœ°æ–¹ã€‚å¿«å»å‘Šè¯‰ä»–çš„é—¨å¾’ï¼Œè¯´ä»–ä»æ­»é‡Œå¤æ´»äº†ï¼Œå¹¶ä¸”åœ¨ä½ ä»¬ä»¥å…ˆå¾€åŠ åˆ©åˆ©å»ï¼Œåœ¨é‚£é‡Œä½ ä»¬è¦è§ä»–ã€‚çœ‹å“ªï¼Œæˆ‘å·²ç»å‘Šè¯‰ä½ ä»¬äº†ã€‚â€
(é©¬å¤ªç¦éŸ³ 28:5-7 å’Œåˆæœ¬)
å¿«å»å‘Šè¯‰ä»–çš„é—¨å¾’ï¼šâ€˜ä»–å·²ç»ä»æ­»äººä¸­å¤æ´»äº†ã€‚ä»–ä¼šæ¯”ä½ ä»¬å…ˆåˆ°åŠ åˆ©åˆ©å»ï¼Œä½ ä»¬åœ¨é‚£é‡Œå¿…çœ‹è§ä»–ã€‚â€™ç°åœ¨æˆ‘å·²ç»å‘Šè¯‰ä½ ä»¬äº†ã€‚â€
(é©¬å¤ªç¦éŸ³ 28:7 æ–°è¯‘æœ¬)
æˆ‘å‘Šè¯‰ä½ ä»¬ï¼Œä¸€ä¸ªç½ªäººæ‚”æ”¹ï¼Œåœ¨å¤©ä¸Šä¹Ÿè¦è¿™æ ·ä¸ºä»–æ¬¢å–œï¼Œè¾ƒæ¯”ä¸ºä¹åä¹ä¸ªä¸ç”¨æ‚”æ”¹çš„ä¹‰äººæ¬¢å–œæ›´å¤§ã€‚â€
(è·¯åŠ ç¦éŸ³ 15:7 å’Œåˆæœ¬)
æˆ‘å‘Šè¯‰ä½ ä»¬ï¼Œå› ä¸ºä¸€ä¸ªç½ªäººæ‚”æ”¹ï¼Œå¤©ä¸Šä¹Ÿè¦è¿™æ ·ä¸ºä»–æ¬¢ä¹ï¼Œæ¯”ä¸ºä¹åä¹ä¸ªä¸ç”¨æ‚”æ”¹çš„ä¹‰äººæ¬¢ä¹æ›´å¤§ã€‚
(è·¯åŠ ç¦éŸ³ 15:7 æ–°è¯‘æœ¬)
å¦‡å¥³ä»¬å°±æ€¥å¿™ç¦»å¼€åŸå¢“ï¼Œåˆå®³æ€•ï¼Œåˆå¤§å¤§åœ°æ¬¢å–œï¼Œè·‘å»è¦æŠ¥ç»™ä»–çš„é—¨å¾’ã€‚
(é©¬å¤ªç¦éŸ³ 28:8)

ä¼Šåˆ©èç™½ä¸€å¬é©¬åˆ©äºšé—®å®‰ï¼Œæ‰€æ€€çš„èƒå°±åœ¨è…¹é‡Œè·³åŠ¨ã€‚ä¼Šåˆ©èç™½ä¸”è¢«åœ£çµå……æ»¡ï¼Œé«˜å£°å–Šç€è¯´ï¼šâ€œä½ åœ¨å¦‡å¥³ä¸­æ˜¯æœ‰ç¦çš„ï¼ä½ æ‰€æ€€çš„èƒä¹Ÿæ˜¯æœ‰ç¦çš„ï¼æˆ‘ä¸»çš„æ¯åˆ°æˆ‘è¿™é‡Œæ¥ï¼Œè¿™æ˜¯ä»å“ªé‡Œå¾—çš„å‘¢ï¼Ÿå› ä¸ºä½ é—®å®‰çš„å£°éŸ³ä¸€å…¥æˆ‘è€³ï¼Œæˆ‘è…¹é‡Œçš„èƒå°±æ¬¢å–œè·³åŠ¨ã€‚è¿™ç›¸ä¿¡çš„å¥³å­æ˜¯æœ‰ç¦çš„ï¼å› ä¸ºä¸»å¯¹å¥¹æ‰€è¯´çš„è¯éƒ½è¦åº”éªŒã€‚â€
(è·¯åŠ ç¦éŸ³ 1:41-45 å’Œåˆæœ¬)
è¿™ç›¸ä¿¡ä¸»ä¼ ç»™å¥¹çš„è¯å¿…è¦æˆå°±çš„å¥³å­æ˜¯æœ‰ç¦çš„ã€‚â€
(è·¯åŠ ç¦éŸ³ 1:45 æ–°è¯‘æœ¬)
é‚£ç›¸ä¿¡ä¸»æ‰€è¯´çš„è¯å¿…å®šå®ç°çš„å¥³å­æœ‰ç¦äº†ï¼â€
(è·¯åŠ ç¦éŸ³ 1:45 å½“ä»£è¯‘æœ¬)

è¶…è¶Šå¸¸è§„çš„ä¿¡å¿ƒ

å½“å¤©ä½¿å®£å¸ƒé©¬åˆ©äºšå°†æ€€ä¸Šç¥çš„å„¿å­æ—¶ï¼Œå¥¹è¿˜æ˜¯ä¸€ä¸ªåœ¨æ‹¿æ’’å‹’å°åŸé‡Œè¿‡ç€å®é™ç”Ÿæ´»çš„å°‘å¥³ï¼ˆè·¯åŠ ç¦éŸ³ 1:31ï¼‰ã€‚ä¸€èˆ¬äººè¦æ˜¯å¬åˆ°è¿™æ ·çš„æ¶ˆæ¯ï¼Œæœ¬èƒ½çš„ååº”å¯èƒ½æ˜¯ææƒ§ã€éœ‡æƒŠæˆ–æ•¬ç•ã€‚ç„¶è€Œï¼Œé©¬åˆ©äºšçš„ååº”å´æ˜¯ç›¸ä¿¡â€”â€”ç›¸ä¿¡å¤©ä½¿å‘Šè¯‰å¥¹çš„æ˜¯äº‹å®ã€‚å¥¹å¯¹å¤©ä½¿è¯´ï¼šâ€œæˆ‘æ˜¯ä¸»çš„ä½¿å¥³ï¼Œæƒ…æ„¿ç…§ä½ çš„è¯æˆå°±åœ¨æˆ‘èº«ä¸Šã€‚â€ï¼ˆè·¯åŠ ç¦éŸ³ 1:38ï¼‰ã€‚ 

é©¬åˆ©äºšçš„è¡¨å§ä¼Šåˆ©èç™½ç›®ç¹äº†å¥¹å¦‚æ­¤åšå®šä¸ç§»çš„ä¿¡å¿ƒï¼Œåœ¨åœ£çµçš„æ„ŸåŠ¨ä¸‹é«˜å£°ç¥ç¦é©¬åˆ©äºšå’Œè®¤å¯å¥¹çš„ä¿¡å¿ƒï¼šâ€œè¿™ç›¸ä¿¡çš„å¥³å­æ˜¯æœ‰ç¦çš„ï¼å› ä¸ºä¸»å¯¹å¥¹æ‰€è¯´çš„è¯éƒ½è¦åº”éªŒã€‚â€

åœ¨è¿™äº›ç®€å•çš„è¯è¯­ä¸­ï¼Œæˆ‘ä»¬å—åˆ°æé†’è¦å°†æˆ‘ä»¬çš„ä¿¡å¿ƒé”šå®šåœ¨åšå®šä¸ç§»çš„çœŸç†ä¸Šï¼Œé‚£å°±æ˜¯ç¥ä¼šæŒ‰ç…§ä»–çš„è¯è¯­ä¿¡å®åœ°å±¥è¡Œä»–çš„åº”è®¸ã€‚ä¼Šåˆ©èç™½çš„å®£å‘Šâ€”â€”â€œè¿™ç›¸ä¿¡çš„å¥³å­æ˜¯æœ‰ç¦çš„â€â€”â€”ä¸ä»…ä»…æ˜¯ä¸€ä¸ªè§‚å¯Ÿï¼Œä¹Ÿæ˜¯ä¸€ç§å½“ä¸‹çš„è‚¯å®šã€‚é‡ç‚¹ä¸ä»…åœ¨äºè¿™äº›åº”è®¸å¿…å°†å®ç°ï¼Œè¿˜åœ¨äºå› ç›¸ä¿¡å’Œä»°èµ–ç¥çš„è®¡åˆ’è€Œå¸¦æ¥çš„ç¥ç¦ã€‚å®ƒä¿ƒä½¿æˆ‘ä»¬å®¡è§†è‡ªå·±çš„ä¿¡å¿ƒä¹‹æ—…ã€‚æˆ‘ä»¬æ˜¯å¦åƒé©¬åˆ©äºšä¸€æ ·ï¼Œé€‰æ‹©é¡ºæœå¹¶ä»°èµ–äºç¥çš„åº”è®¸ï¼Ÿ

ä»Šå¤©ï¼Œä½ åœ¨ç¥·å‘Šä¸­å¯»æ±‚ä¸»ä¹‹é™…ï¼Œè¦å¯¹æ„å¤–çš„ç¥ç¦è¡¨ç¤ºæ„Ÿæ¿€ã€‚ç¥ˆæ±‚æ´å¯ŸåŠ›æ¥è¯†åˆ«ç¥çš„æ‰‹åœ¨åšå·¥ï¼Œå³ä½¿ä½ çš„å¤„å¢ƒçœ‹æ¥ä¼¼ä¹å®Œå…¨ç›¸åã€‚

ç¥·å‘Š
ç¥å•Šï¼Œå°½ç®¡æˆ‘å¿ƒå­˜ç–‘è™‘å’Œææƒ§ï¼Œæˆ‘è¿˜æ˜¯è¦æ¥åˆ°ä½ é¢å‰ã€‚æ— è®ºä½ æŠŠæˆ‘å¼•å‘ä½•æ–¹ï¼Œæˆ‘é€‰æ‹©ç›¸ä¿¡å¹¶ä»°èµ–ä½ çš„å¤§èƒ½å’Œåº”è®¸ã€‚æ±‚ä½ å¢å¼ºå¹¶ç¥ç¦æˆ‘çš„ä¿¡å¿ƒã€‚è®©æˆ‘å……æ»¡æ´å¯ŸåŠ›å’Œæ„Ÿæ©ä¹‹å¿ƒã€‚å¥‰è€¶ç¨£çš„åï¼Œé˜¿ä»¬ã€‚
"""

# Generate filename dynamically
# 1. Extract Date
TEXT = clean_text(TEXT)
first_line = TEXT.strip().split('\n')[0]
date_match = re.search(r"(\d{1,2})/(\d{1,2})/(\d{4})", first_line)
if date_match:
    m, d, y = date_match.groups()
    date_str = f"{y}-{int(m):02d}-{int(d):02d}"
else:
    # Try YYYY-MM-DD
    date_match = re.search(r"(\d{4})-(\d{1,2})-(\d{1,2})", first_line)
    if date_match:
        y, m, d = date_match.groups()
        date_str = f"{y}-{int(m):02d}-{int(d):02d}"
    else:
        date_str = datetime.today().strftime("%Y-%m-%d")

# 2. Extract Verse
# Handle both English () and Chinese ï¼ˆï¼‰ parentheses, and both : and ï¼š colons
verse_ref = filename_parser.extract_verse_from_text(TEXT)

if verse_ref:
    extracted_prefix = CLI_PREFIX if CLI_PREFIX else filename_parser.extract_filename_prefix(TEXT)
    filename = filename_parser.generate_filename(verse_ref, date_str, extracted_prefix).replace(".mp3", "_edge.mp3")
else:
    filename = f"{date_str}_edge.mp3"
OUTPUT_DIR = os.path.join(os.getcwd(), "output")
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
OUTPUT_PATH = os.path.join(OUTPUT_DIR, filename)
print(f"Target Output: {OUTPUT_PATH}")

# Convert Bible references in the text (e.g., 'ç½—é©¬ä¹¦ 1:17' to 'ç½—é©¬ä¹¦ 1ç« 17ç¯€')
TEXT = convert_bible_reference(TEXT)
TEXT = convert_dates_in_text(TEXT)
TEXT = clean_text(TEXT)
# Split the text into paragraphs
paragraphs = [p.strip() for p in re.split(r'\n{2,}', TEXT.strip()) if p.strip()]
first_paragraphs = [paragraphs[0]] # First paragraph (introduction)
second_paragraphs = [paragraphs[1]] # Second paragraph
third_paragraphs = [paragraphs[2]] # Third paragraph
fourth_paragraphs = ["\n\n".join(paragraphs[3:-1])] # Paragraphs between 3rd and last
fifth_paragraphs = [paragraphs[-1]] # Last paragraph
"""
Locale,ShortName,Gender,Voice Personalities,Content Categories
zh-CN,zh-CN-XiaoxiaoNeural,Female,Warm,"News, Novel"
zh-CN,zh-CN-XiaoyiNeural,Female,Lively,"Cartoon, Novel"
zh-CN,zh-CN-YunjianNeural,Male,Passion,"Sports, Novel"
zh-CN,zh-CN-YunxiNeural,Male,"Lively, Sunshine",Novel
zh-CN,zh-CN-YunxiaNeural,Male,Cute,"Cartoon, Novel"
zh-CN,zh-CN-YunyangNeural,Male,"Professional, Reliable",News
zh-CN-liaoning,zh-CN-liaoning-XiaobeiNeural,Female,Humorous,Dialect
zh-CN-shaanxi,zh-CN-shaanxi-XiaoniNeural,Female,Bright,Dialect
zh-HK,zh-HK-HiuGaaiNeural,Female,"Friendly, Positive",General
zh-HK,zh-HK-HiuMaanNeural,Female,"Friendly, Positive",General
zh-HK,zh-HK-WanLungNeural,Male,"Friendly, Positive",General
zh-TW,zh-TW-HsiaoChenNeural,Female,"Friendly, Positive",General
zh-TW,zh-TW-HsiaoYuNeural,Female,"Friendly, Positive",General
zh-TW,zh-TW-YunJheNeural,Male,"Friendly, Positive",General
"""
# Voice settings
FIRST_VOICE = "zh-CN-YunxiNeural" # First voice (introduction)
SECOND_VOICE = "zh-CN-XiaoyiNeural" # Second voice (second paragraph)
THIRD_VOICE = "zh-CN-YunyangNeural" # Third voice (third paragraph)
FOURTH_VOICE = "zh-CN-XiaoxiaoNeural" # Fourth voice (paragraphs between 3rd and last)
FIFTH_VOICE = "zh-CN-YunxiaNeural" # Fifth voice (last paragraph)
#THIRD_VOICE = "zh-CN-XiaoxiaoNeural" # Second voice (second paragraph)

TEMP_DIR = OUTPUT_DIR + os.sep # For temp files
TEMP_FIRST = os.path.join(OUTPUT_DIR, "temp_first_verse.mp3")
TEMP_SECOND = os.path.join(OUTPUT_DIR, "temp_second_verse.mp3")
TEMP_THIRD = os.path.join(OUTPUT_DIR, "temp_third_verse.mp3")

# Alias for backward compatibility with main()
OUTPUT = OUTPUT_PATH
async def generate_audio(text, voice, output_file):
    print(f"DEBUG: Text to read: {text[:100]}...")
    # print(f"DEBUG: Generating audio for text: '{text[:50]}...' (len={len(text)})")
    communicate = edge_tts.Communicate(text=text, voice=voice, rate=TTS_RATE)
    await communicate.save(output_file)
async def main():
    # Group paragraphs
    if len(paragraphs) < 5:
        logical_sections = [[p] for p in paragraphs]
    else:
        logical_sections = [
            [paragraphs[0]],              # Intro
            [paragraphs[1]],              # Scripture 1
            [paragraphs[2]],              # Scripture 2
            paragraphs[3:-1],             # Main Body
            [paragraphs[-1]]              # Prayer
        ]

    # Voice mapping
    voices = [FIRST_VOICE, SECOND_VOICE, THIRD_VOICE, FOURTH_VOICE, FIFTH_VOICE]
    section_titles = ["Intro", "Scripture 1", "Scripture 2", "Main Body", "Prayer"]
    
    print(f"Processing {len(logical_sections)} logical sections...")
    final_segments = []
    global_p_index = 0

    for i, section_paras in enumerate(logical_sections):
        title = section_titles[i] if i < len(section_titles) else f"Section {i+1}"
        print(f"--- Section {i+1}: {title} ---")
        
        section_audio = AudioSegment.empty()
        silence_between_paras = AudioSegment.silent(duration=700) # Edge TTS often returns 24k or 44.1k, pydub handles mixing usually

        for j, para in enumerate(section_paras):
            voice = voices[global_p_index % len(voices)]
            print(f"  > Part {i+1}.{j+1} - {voice} ({len(para)} chars)")
            global_p_index += 1
            
            # Edge TTS requires temp file
            temp_file = f"{TEMP_DIR}temp_v{i}_p{j}.mp3"
            await generate_audio(para, voice, temp_file)
            
            try:
                segment = AudioSegment.from_mp3(temp_file)
                section_audio += segment
                if j < len(section_paras) - 1:
                    section_audio += silence_between_paras
            finally:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
        
        final_segments.append(section_audio)

    # Combine all sections
    final = AudioSegment.empty()
    silence_sections = AudioSegment.silent(duration=1000)

    for i, seg in enumerate(final_segments):
        final += seg
        if i < len(final_segments) - 1:
            final += silence_sections

    # Add Background Music (Optional)
    if ENABLE_BGM:
        print(f"ğŸµ Mixing Background Music (Vol={BGM_VOLUME}dB, Intro={BGM_INTRO_DELAY}ms)...")
        final = audio_mixer.mix_bgm(
            final, 
            specific_filename=BGM_FILE,
            volume_db=BGM_VOLUME,
            intro_delay_ms=BGM_INTRO_DELAY
        )

    # Metadata extraction
    PRODUCER = "VI AI Foundation"
    TITLE = TEXT.strip().split('\n')[0]

    final.export(OUTPUT, format="mp3", tags={'title': TITLE, 'artist': PRODUCER})
    print(f"âœ… Combined audio saved: {OUTPUT}")

if __name__ == "__main__":
    asyncio.run(main())
